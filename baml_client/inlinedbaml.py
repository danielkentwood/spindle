# ----------------------------------------------------------------------------
#
#  Welcome to Baml! To use this generated code, please run the following:
#
#  $ pip install baml
#
# ----------------------------------------------------------------------------

# This file was generated by BAML: please do not edit it. Instead, edit the
# BAML files and re-generate this code using: baml-cli generate
# baml-cli is available with the baml package.

_file_map = {

    "clients.baml": "// Learn more about clients at https://docs.boundaryml.com/docs/snippets/clients/overview\n\n// Using the new OpenAI Responses API for enhanced formatting\nclient<llm> CustomGPT5 {\n  provider openai-responses\n  options {\n    model \"gpt-5\"\n    api_key env.OPENAI_API_KEY\n  }\n}\n\nclient<llm> CustomGPT5Mini {\n  provider openai-responses\n  retry_policy Exponential\n  options {\n    model \"gpt-5-mini\"\n    api_key env.OPENAI_API_KEY\n  }\n}\n\n// Openai with chat completion\nclient<llm> CustomGPT5Chat {\n  provider openai\n  options {\n    model \"gpt-5\"\n    api_key env.OPENAI_API_KEY\n  }\n}\n\n// Latest Anthropic Claude 4 models\nclient<llm> CustomOpus4 {\n  provider anthropic\n  options {\n    model \"claude-opus-4-1-20250805\"\n    api_key env.ANTHROPIC_API_KEY\n  }\n}\n\nclient<llm> CustomSonnet4 {\n  provider anthropic\n  options {\n    model \"claude-sonnet-4-20250514\"\n    api_key env.ANTHROPIC_API_KEY\n  }\n}\n\nclient<llm> CustomHaiku {\n  provider anthropic\n  retry_policy Constant\n  options {\n    model \"claude-3-5-haiku-20241022\"\n    api_key env.ANTHROPIC_API_KEY\n  }\n}\n\n// Example Google AI client (uncomment to use)\n// client<llm> CustomGemini {\n//   provider google-ai\n//   options {\n//     model \"gemini-2.5-pro\"\n//     api_key env.GOOGLE_API_KEY\n//   }\n// }\n\n// Example AWS Bedrock client (uncomment to use)\n// client<llm> CustomBedrock {\n//   provider aws-bedrock\n//   options {\n//     model \"anthropic.claude-sonnet-4-20250514-v1:0\"\n//     region \"us-east-1\"\n//     // AWS credentials are auto-detected from env vars\n//   }\n// }\n\n// Example Azure OpenAI client (uncomment to use)\n// client<llm> CustomAzure {\n//   provider azure-openai\n//   options {\n//     model \"gpt-5\"\n//     api_key env.AZURE_OPENAI_API_KEY\n//     base_url \"https://MY_RESOURCE_NAME.openai.azure.com/openai/deployments/MY_DEPLOYMENT_ID\"\n//     api_version \"2024-10-01-preview\"\n//   }\n// }\n\n// Example Vertex AI client (uncomment to use)\n// client<llm> CustomVertex {\n//   provider vertex-ai\n//   options {\n//     model \"gemini-2.5-pro\"\n//     location \"us-central1\"\n//     // Uses Google Cloud Application Default Credentials\n//   }\n// }\n\n// Example Ollama client for local models (uncomment to use)\n// client<llm> CustomOllama {\n//   provider openai-generic\n//   options {\n//     base_url \"http://localhost:11434/v1\"\n//     model \"llama4\"\n//     default_role \"user\" // Most local models prefer the user role\n//     // No API key needed for local Ollama\n//   }\n// }\n\n// https://docs.boundaryml.com/docs/snippets/clients/round-robin\nclient<llm> CustomFast {\n  provider round-robin\n  options {\n    // This will alternate between the two clients\n    strategy [CustomGPT5Mini, CustomHaiku]\n  }\n}\n\n// https://docs.boundaryml.com/docs/snippets/clients/fallback\nclient<llm> OpenaiFallback {\n  provider fallback\n  options {\n    // This will try the clients in order until one succeeds\n    strategy [CustomGPT5Mini, CustomGPT5]\n  }\n}\n\n// https://docs.boundaryml.com/docs/snippets/clients/retry\nretry_policy Constant {\n  max_retries 3\n  strategy {\n    type constant_delay\n    delay_ms 200\n  }\n}\n\nretry_policy Exponential {\n  max_retries 2\n  strategy {\n    type exponential_backoff\n    delay_ms 300\n    multiplier 1.5\n    max_delay_ms 10000\n  }\n}",
    "generators.baml": "// This helps use auto generate libraries you can use in the language of\n// your choice. You can have multiple generators if you use multiple languages.\n// Just ensure that the output_dir is different for each generator.\ngenerator target {\n    // Valid values: \"python/pydantic\", \"typescript\", \"ruby/sorbet\", \"rest/openapi\"\n    output_type \"python/pydantic\"\n\n    // Where the generated code will be saved (relative to baml_src/)\n    output_dir \"../\"\n\n    // The version of the BAML package you have installed (e.g. same version as your baml-py or @boundaryml/baml).\n    // The BAML VSCode extension version should also match this version.\n    version \"0.211.2\"\n\n    // Valid values: \"sync\", \"async\"\n    // This controls what `b.FunctionName()` will be (sync or async).\n    default_client_mode sync\n}\n",
    "resume.baml": "// Defining a data model.\nclass Resume {\n  name string\n  email string\n  experience string[]\n  skills string[]\n}\n\n// Create a function to extract the resume from a string.\nfunction ExtractResume(resume: string) -> Resume {\n  // Specify a client as provider/model-name\n  // You can also use custom LLM params with a custom client name from clients.baml like \"client CustomGPT5\" or \"client CustomSonnet4\"\n  client \"openai-responses/gpt-5-mini\" // Set OPENAI_API_KEY to use this client.\n  prompt #\"\n    Extract from this content:\n    {{ resume }}\n\n    {{ ctx.output_format }}\n  \"#\n}\n\n\n\n// Test the function with a sample resume. Open the VSCode playground to run this.\ntest vaibhav_resume {\n  functions [ExtractResume]\n  args {\n    resume #\"\n      Vaibhav Gupta\n      vbv@boundaryml.com\n\n      Experience:\n      - Founder at BoundaryML\n      - CV Engineer at Google\n      - CV Engineer at Microsoft\n\n      Skills:\n      - Rust\n      - C++\n    \"#\n  }\n}\n",
    "spindle.baml": "// Spindle: Knowledge Graph Triple Extraction\n// This file defines the data structures and extraction function for building knowledge graphs from text\n\n// Source metadata for tracking where a triple came from\nclass SourceMetadata {\n  source_name string @description(\"The name or identifier of the source document\")\n  source_url string? @description(\"Optional URL of the source document\")\n}\n\n// Character span indicating text evidence for a triple\nclass CharacterSpan {\n  text string @description(\"The exact text from the source that supports this triple\")\n  start int? @description(\"Starting character index in the source text (0-based, computed in post-processing)\")\n  end int? @description(\"Ending character index in the source text (exclusive, computed in post-processing)\")\n}\n\n// A triple represents a subject-predicate-object relationship with supporting evidence\nclass Triple {\n  subject string @description(\"The subject entity of the triple\")\n  predicate string @description(\"The relationship/predicate connecting subject and object\")\n  object string @description(\"The object entity of the triple\")\n  source SourceMetadata @description(\"Metadata about the source of this triple\")\n  supporting_spans CharacterSpan[] @description(\"Character spans in the source text that support this triple\")\n  extraction_datetime string? @description(\"ISO 8601 datetime when this triple was extracted (set automatically in post-processing)\")\n}\n\n// Defines a type of entity that can appear in the knowledge graph\nclass EntityType {\n  name string @description(\"The name of the entity type (e.g., 'Person', 'Organization')\")\n  description string @description(\"A description of what this entity type represents\")\n}\n\n// Defines a type of relationship between entities\nclass RelationType {\n  name string @description(\"The name of the relation type (e.g., 'works_at', 'located_in')\")\n  description string @description(\"A description of what this relation represents\")\n  domain string @description(\"The entity type that can be the subject of this relation\")\n  range string @description(\"The entity type that can be the object of this relation\")\n}\n\n// An ontology defines the structure of the knowledge graph\nclass Ontology {\n  entity_types EntityType[] @description(\"List of valid entity types\")\n  relation_types RelationType[] @description(\"List of valid relation types\")\n}\n\n// The result of triple extraction\nclass ExtractionResult {\n  triples Triple[] @description(\"List of extracted triples from the text\")\n  reasoning string @description(\"Explanation of the extraction decisions and entity consistency choices\")\n}\n\n// Main function to extract knowledge graph triples from text\nfunction ExtractTriples(\n  text: string,\n  ontology: Ontology,\n  source_metadata: SourceMetadata,\n  existing_triples: Triple[]\n) -> ExtractionResult {\n  client CustomSonnet4\n  prompt #\"\n    You are a knowledge graph extraction expert. Your task is to extract structured triples (subject-predicate-object) from the provided text, along with supporting evidence.\n\n    {{ _.role(\"user\") }}\n    \n    ONTOLOGY:\n    You must extract triples that conform to the following ontology:\n    \n    Valid Entity Types:\n    {% for entity_type in ontology.entity_types %}\n    - {{ entity_type.name }}: {{ entity_type.description }}\n    {% endfor %}\n    \n    Valid Relation Types:\n    {% for relation_type in ontology.relation_types %}\n    - {{ relation_type.name }}: {{ relation_type.description }}\n      (Domain: {{ relation_type.domain }}, Range: {{ relation_type.range }})\n    {% endfor %}\n    \n    SOURCE METADATA:\n    Source Name: {{ source_metadata.source_name }}\n    {% if source_metadata.source_url %}\n    Source URL: {{ source_metadata.source_url }}\n    {% endif %}\n    \n    EXISTING TRIPLES:\n    {% if existing_triples|length > 0 %}\n    The following triples have already been extracted from OTHER sources. You MUST:\n    1. Use consistent entity names - if an entity appears in existing triples, use the EXACT same name\n    2. Maintain entity identity - recognize when entities in the new text are the same as entities in existing triples\n    3. Duplicate triples ARE ALLOWED if they come from different sources (different source names)\n    4. If you extract the same fact that exists in existing triples, it's okay as long as it's from this new source\n    \n    {% for triple in existing_triples %}\n    - {{ triple.subject }} -> {{ triple.predicate }} -> {{ triple.object }} (from: {{ triple.source.source_name }})\n    {% endfor %}\n    {% else %}\n    This is the first extraction, so there are no existing triples to consider.\n    {% endif %}\n    \n    TEXT TO ANALYZE:\n    {{ text }}\n    \n    INSTRUCTIONS:\n    1. Extract all meaningful triples from the text that conform to the ontology\n    2. Only use entity types and relation types defined in the ontology\n    3. Use clear, consistent entity names (e.g., \"John Smith\" not \"John\" or \"Smith\")\n    4. If an entity appears in existing triples, use the exact same name for consistency\n    5. For each triple, identify the TEXT SPANS that provide evidence for the triple\n       - Copy the EXACT text from the source that supports the triple\n       - You can include multiple text spans if the evidence is spread across different parts of the text\n       - Be precise - copy the text exactly as it appears, including punctuation and spacing\n       - Include enough context to make the evidence clear\n    6. Set the source metadata for each triple to the provided source information\n    7. Provide reasoning explaining your extraction decisions, entity consistency choices, and how you identified supporting spans\n    \n    EXAMPLE of text spans:\n    If the text is \"Alice works at TechCorp in San Francisco.\" and you extract the triple (Alice, works_at, TechCorp),\n    the supporting span text would be: \"Alice works at TechCorp\"\n    \n    Note: You only need to provide the text content. Character indices will be computed automatically in post-processing.\n    \n    {{ ctx.output_format }}\n  \"#\n}\n\n",
}

def get_baml_files():
    return _file_map