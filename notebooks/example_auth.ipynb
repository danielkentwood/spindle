{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## LLM Authentication Examples\n",
        "\n",
        "This notebook demonstrates the different ways to authenticate and access LLMs with Spindle, including:\n",
        "\n",
        "- **Auto-Detection:** Automatically detect and use GCP Vertex AI credentials when available\n",
        "- **Explicit Vertex AI Configuration:** Manually configure Vertex AI with project ID and region\n",
        "- **Mixed Authentication:** Use Vertex AI for some models, direct API keys for others\n",
        "- **Direct API Keys:** Traditional approach using `ANTHROPIC_API_KEY` and `OPENAI_API_KEY`\n",
        "\n",
        "### Key Features\n",
        "\n",
        "- **Preference for Vertex AI:** When both GCP credentials and API keys are available, Vertex AI is preferred\n",
        "- **Automatic Fallback:** If Vertex AI auth fails, automatically falls back to direct API keys\n",
        "- **Support for Multiple Providers:** Anthropic (Claude), OpenAI (GPT), and Google (Gemini) models\n",
        "- **Both SDK and API Approaches:** Supports Anthropic Vertex SDK and MAAS API methods\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Setup\n",
        "\n",
        "First, let's import the necessary modules:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os  # 'os' imported but unused\n",
        "import sys  # 'sys' imported but unused\n",
        "from pprint import pprint\n",
        "\n",
        "# Import Spindle components\n",
        "from spindle import SpindleExtractor, create_ontology\n",
        "from spindle.llm_config import (\n",
        "    LLMConfig,\n",
        "    detect_available_auth,\n",
        "    setup_llm_config,  # 'spindle.llm_config.setup_llm_config' imported but unused\n",
        "    get_anthropic_vertex_client,  # 'spindle.llm_config.get_anthropic_vertex_client' imported but unused\n",
        "    create_vertex_maas_request,  # 'spindle.llm_config.create_vertex_maas_request' imported but unused\n",
        "    AuthMethod,\n",
        "    Provider,\n",
        ")\n",
        "\n",
        "print(\"✅ Imports successful\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Section 1: Auto-Detection\n",
        "\n",
        "The simplest approach - let Spindle automatically detect available credentials and choose the best authentication method.\n",
        "\n",
        "### How Auto-Detection Works\n",
        "\n",
        "1. Check for GCP Vertex AI credentials:\n",
        "   - `GOOGLE_APPLICATION_CREDENTIALS` environment variable\n",
        "   - Default GCP credentials (via `gcloud auth application-default login`)\n",
        "   - `GCP_PROJECT_ID` and `GCP_REGION` environment variables\n",
        "\n",
        "2. Check for direct API keys:\n",
        "   - `ANTHROPIC_API_KEY`\n",
        "   - `OPENAI_API_KEY`\n",
        "   - `GOOGLE_API_KEY`\n",
        "\n",
        "**Prefer Vertex AI:** If both GCP and API keys are available, Vertex AI is preferred\n",
        "\n",
        "Let's see what credentials are detected:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Detect available authentication methods\n",
        "config = detect_available_auth()\n",
        "\n",
        "print(\"\\n=== Detected Configuration ===\")\n",
        "pprint(config.to_dict())\n",
        "\n",
        "print(\"\\n=== Authentication Method Selection ===\")\n",
        "for provider in Provider.ANTHROPIC, Provider.OPENAI, Provider.GOOGLE:\n",
        "    auth_method = config.get_auth_method_for_provider(provider)\n",
        "    print(f\"{provider.value:12} -> {auth_method.value if auth_method else 'Not available'}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Using Auto-Detection with SpindleExtractor\n",
        "\n",
        "When you create a `SpindleExtractor` without specifying `llm_config`, it automatically detects credentials:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define a simple ontology\n",
        "entity_types = [\n",
        "    {\"name\": \"Person\", \"description\": \"A human being\"},\n",
        "    {\"name\": \"Organization\", \"description\": \"A company or institution\"},\n",
        "    {\"name\": \"Location\", \"description\": \"A place or geographical location\"},\n",
        "]\n",
        "\n",
        "relation_types = [\n",
        "    {\"name\": \"works_at\", \"description\": \"Employment relationship\", \"domain\": \"Person\", \"range\": \"Organization\"},\n",
        "    {\"name\": \"located_in\", \"description\": \"Location relationship\", \"domain\": \"Organization\", \"range\": \"Location\"},\n",
        "]\n",
        "\n",
        "ontology = create_ontology(entity_types, relation_types)\n",
        "\n",
        "# Create extractor with auto-detection (default behavior)\n",
        "extractor = SpindleExtractor(ontology=ontology, auto_detect_auth=True)\n",
        "\n",
        "print(f\"Extractor configured with: {extractor.llm_config.preferred_auth_method.value if extractor.llm_config else 'No config'}\")\n",
        "print(f\"Available methods: {[m.value for m in extractor.llm_config.available_auth_methods] if extractor.llm_config else []}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Extract triples using auto-detected credentials\n",
        "text = \"Alice Johnson works at TechCorp, which is located in San Francisco.\"\n",
        "\n",
        "try:\n",
        "    result = extractor.extract(text, source_name=\"example_auto\")\n",
        "    print(f\"✅ Extracted {len(result.triples)} triples\")\n",
        "    for triple in result.triples:\n",
        "        print(f\"- {(triple.subject.name)} -> {triple.predicate} -> {triple.object.name} ({triple.object.type})\")\n",
        "except Exception as exc:\n",
        "    print(f\"❌ Extraction failed: {exc}\")\n",
        "    print(\"⚠️ Note: This might be because no valid credentials were detected.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Section 2: Explicit Vertex AI Configuration\n",
        "\n",
        "Sometimes you want to explicitly configure Vertex AI credentials, especially when:\n",
        "- You have multiple GCP projects\n",
        "- You want to use a specific region\n",
        "- You want to override auto-detection\n",
        "\n",
        "### Approach 1: Using Anthropic Vertex AI SDK\n",
        "\n",
        "This is the recommended approach for Anthropic models via Vertex AI:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Explicit configuration for Vertex AI\n",
        "vertex_config = LLMConfig(\n",
        "    gcp_project_id=\"your-project-id\",  # Replace with your project ID\n",
        "    gcp_region=\"us-east5\",  # Claude Sonnet 4 is available in us-east5\n",
        "    preferred_auth_method=AuthMethod.VERTEX_AI,\n",
        ")\n",
        "\n",
        "print(\"=== Explicit Vertex AI Configuration ===\")\n",
        "print(f\"Project ID: {vertex_config.gcp_project_id}\")\n",
        "print(f\"Region: {vertex_config.gcp_region}\")\n",
        "print(f\"Has Vertex AI auth: {vertex_config.has_vertex_ai_auth()}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Summary\n",
        "\n",
        "This notebook demonstrated four approaches to LLM authentication with Spindle:\n",
        "\n",
        "1. **Auto-Detection** (Recommended): Let Spindle detect and choose the best method\n",
        "2. **Explicit Vertex AI**: Manually configure GCP project and region\n",
        "3. **Mixed Authentication**: Use different methods for different providers\n",
        "4. **Direct API Keys**: Traditional approach with API keys\n",
        "\n",
        "### Quick Start Guide\n",
        "\n",
        "```python\n",
        "# Option 1: Auto-detection (easiest)\n",
        "extractor = SpindleExtractor(ontology)\n",
        "# That's it! Spindle will detect and use the best available auth method\n",
        "\n",
        "# Option 2: Explicit Vertex AI\n",
        "from spindle.llm_config import LLMConfig, AuthMethod\n",
        "config = LLMConfig(\n",
        "    gcp_project_id=\"your-project\",\n",
        "    gcp_region=\"us-east5\",\n",
        "    preferred_auth_method=AuthMethod.VERTEX_AI,\n",
        ")\n",
        "extractor = SpindleExtractor(ontology, llm_config=config)\n",
        "\n",
        "# Option 3: Direct API keys only\n",
        "Just set environment variables:\n",
        "export ANTHROPIC_API_KEY=...\n",
        "export OPENAI_API_KEY=...\n",
        "extractor = SpindleExtractor(ontology)  # Will use API keys\n",
        "```\n",
        "\n",
        "### Next Steps\n",
        "\n",
        "- See `docs/VERTEX_AI_SETUP.md` for detailed Vertex AI configuration\n",
        "- See `docs/QUICKSTART.md` for general Spindle usage\n",
        "- Check other example notebooks for specific use cases\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
